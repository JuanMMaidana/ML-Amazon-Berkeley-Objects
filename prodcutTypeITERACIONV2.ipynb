{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRQ5cq5-e_Yc"
      },
      "source": [
        "# **Importación del dataset ITERACIÓN V2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sin interncion se borraron los outputs del notebook, pero aqui se encuentra el codigo y en el informe las metricas en caso de ser necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "WARNING:tensorflow:From C:\\Users\\delp\\AppData\\Local\\Temp\\ipykernel_8576\\3090823567.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "Is GPU available: True\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Listar todos los dispositivos físicos\n",
        "print(\"Physical devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# Verificar si hay una GPU disponible\n",
        "print(\"Is GPU available:\", tf.test.is_gpu_available())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pynQVAyAOpus"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "images_base_dir = 'images'\n",
        "images_metadata_dir = os.path.join(images_base_dir, 'metadata')\n",
        "images_dir = os.path.join(images_base_dir, 'small')\n",
        "\n",
        "listings_base_dir = 'listings'\n",
        "listings_metadata_dir = os.path.join(listings_base_dir, 'metadata')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20mxnFLJesoM"
      },
      "source": [
        "# **Análisis de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dTOJ1XsKe-7o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "image_metadata = pd.read_csv(os.path.join(images_metadata_dir, 'images.csv.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DNI841pSQrrx",
        "outputId": "1c227f34-a39d-4ffb-841a-5e1d96d558f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>010-mllS7JL</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>14/14fe8812.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01dkn0Gyx0L</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>da/daab0cad.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01sUPg0387L</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>d2/d2daaae9.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1168jc-5r1L</td>\n",
              "      <td>186</td>\n",
              "      <td>186</td>\n",
              "      <td>3a/3a4e88e6.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11RUV5Fs65L</td>\n",
              "      <td>30</td>\n",
              "      <td>500</td>\n",
              "      <td>d9/d91ab9cf.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_id  height  width             path\n",
              "0  010-mllS7JL     106    106  14/14fe8812.jpg\n",
              "1  01dkn0Gyx0L     122    122  da/daab0cad.jpg\n",
              "2  01sUPg0387L     111    111  d2/d2daaae9.jpg\n",
              "3  1168jc-5r1L     186    186  3a/3a4e88e6.jpg\n",
              "4  11RUV5Fs65L      30    500  d9/d91ab9cf.jpg"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "me39mI1mSMln",
        "outputId": "aad919fc-bce0-40d3-c708-0ff41e9be309"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>398212.000000</td>\n",
              "      <td>398212.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1855.255645</td>\n",
              "      <td>1796.569488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>639.266192</td>\n",
              "      <td>609.717916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>65.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1315.000000</td>\n",
              "      <td>1319.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2200.000000</td>\n",
              "      <td>1879.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2400.000000</td>\n",
              "      <td>2400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2871.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              height          width\n",
              "count  398212.000000  398212.000000\n",
              "mean     1855.255645    1796.569488\n",
              "std       639.266192     609.717916\n",
              "min        21.000000      65.000000\n",
              "25%      1315.000000    1319.000000\n",
              "50%      2200.000000    1879.000000\n",
              "75%      2400.000000    2400.000000\n",
              "max      2871.000000    3000.000000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_metadata.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D-YL_nQzKQM",
        "outputId": "d6a74bb9-61a8-4ada-9696-8e125762be8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(398212, 4)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_metadata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1maao3qktnQ",
        "outputId": "42037fc5-bd1c-4a58-cbc1-6527c0c453b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos de metadatos de los listados:\n",
            "  main_image_id           product_type\n",
            "0   81iZlv3bjpL                  SHOES\n",
            "1   619y9YG9cnL               HARDWARE\n",
            "2   81NP7qh2L6L  MECHANICAL_COMPONENTS\n",
            "3   61Rp4qOih9L                   SOFA\n",
            "4   714CmIfKIYL                  SHOES\n",
            "Datos de other_image_id:\n",
            "      image_id main_image_id product_type\n",
            "0  91mIRxgziUL   81iZlv3bjpL        SHOES\n",
            "1  91eqBkW06wL   81iZlv3bjpL        SHOES\n",
            "2  A1BHZSKNbkL   81iZlv3bjpL        SHOES\n",
            "3  51Fqps5k9YL   619y9YG9cnL     HARDWARE\n",
            "4  51lCKFuYuWL   619y9YG9cnL     HARDWARE\n",
            "Datos fusionados:\n",
            "      image_id             path main_image_id product_type\n",
            "0  010-mllS7JL  14/14fe8812.jpg   010-mllS7JL      KITCHEN\n",
            "1  01dkn0Gyx0L  da/daab0cad.jpg   01dkn0Gyx0L      KITCHEN\n",
            "2  01sUPg0387L  d2/d2daaae9.jpg   01sUPg0387L      KITCHEN\n",
            "3  1168jc-5r1L  3a/3a4e88e6.jpg   1168jc-5r1L      KITCHEN\n",
            "4  11RUV5Fs65L  d9/d91ab9cf.jpg   617jhKkKz+L      GROCERY\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define las rutas de los directorios\n",
        "images_base_dir = 'images'\n",
        "images_metadata_dir = os.path.join(images_base_dir, 'metadata')\n",
        "listings_metadata_dir = 'listings/metadata'\n",
        "\n",
        "# Carga los metadatos de las imágenes\n",
        "image_metadata = pd.read_csv(os.path.join(images_metadata_dir, 'images.csv.gz'))\n",
        "\n",
        "# Extraer solo las columnas necesarias de image_metadata\n",
        "image_metadata = image_metadata[['image_id', 'path']]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Procesar todos los archivos JSON comprimidos\n",
        "for file_name in os.listdir(listings_metadata_dir):\n",
        "    if file_name.endswith('.json.gz'):\n",
        "        file_path = os.path.join(listings_metadata_dir, file_name)\n",
        "        \n",
        "        with gzip.open(file_path, 'rt', encoding='ascii') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    item = json.loads(line)\n",
        "                    main_image_id = item.get('main_image_id')\n",
        "                    product_type_value = None\n",
        "\n",
        "                    # Extraer el tipo de producto\n",
        "                    if 'product_type' in item:\n",
        "                        for product_type in item['product_type']:\n",
        "                            product_type_value = product_type.get('value')\n",
        "                            break\n",
        "                    \n",
        "                    # Asegurarse de que main_image_id no sea None\n",
        "                    if main_image_id:\n",
        "                        all_results.append({\n",
        "                            'main_image_id': main_image_id,\n",
        "                            'product_type': product_type_value\n",
        "                        })\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "\n",
        "listing_metadata = pd.DataFrame(all_results)\n",
        "\n",
        "# Verificación de datos extraídos\n",
        "print(\"Datos de metadatos de los listados:\")\n",
        "print(listing_metadata.head())\n",
        "\n",
        "# Unión de los DataFrames usando main_image_id\n",
        "merged_df = image_metadata.merge(listing_metadata, left_on='image_id', right_on='main_image_id', how='left')\n",
        "\n",
        "# Extraer los other_image_id\n",
        "other_results = []\n",
        "\n",
        "for file_name in os.listdir(listings_metadata_dir):\n",
        "    if file_name.endswith('.json.gz'):\n",
        "        file_path = os.path.join(listings_metadata_dir, file_name)\n",
        "\n",
        "        with gzip.open(file_path, 'rt', encoding='ascii') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    item = json.loads(line)\n",
        "                    if 'other_image_id' in item:\n",
        "                        for other_image_id in item['other_image_id']:\n",
        "                            other_results.append({\n",
        "                                'image_id': other_image_id,\n",
        "                                'main_image_id': item.get('main_image_id'),\n",
        "                                'product_type': item['product_type'][0]['value'] if 'product_type' in item and item['product_type'] else None\n",
        "                            })\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "\n",
        "other_metadata = pd.DataFrame(other_results)\n",
        "\n",
        "# Verificación de datos extraídos de other_image_id\n",
        "print(\"Datos de other_image_id:\")\n",
        "print(other_metadata.head())\n",
        "\n",
        "# Unión adicional usando other_image_id\n",
        "merged_df_other = image_metadata.merge(other_metadata, on='image_id', how='left')\n",
        "\n",
        "# Concatenar los dos DataFrames\n",
        "merged_df = pd.concat([merged_df, merged_df_other])\n",
        "\n",
        "# Limpieza de columnas duplicadas y priorización de valores no nulos\n",
        "merged_df = merged_df.groupby('image_id').first().reset_index()\n",
        "\n",
        "# Visualización de los resultados\n",
        "print(\"Datos fusionados:\")\n",
        "print(merged_df.head())\n",
        "\n",
        "# Guardar el DataFrame resultante en un archivo CSV\n",
        "merged_df.to_csv('merged_data_product_type.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "myzLJpU0lANe",
        "outputId": "6aee467a-70e2-4d7d-b20d-4936f1152a1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>path</th>\n",
              "      <th>main_image_id</th>\n",
              "      <th>product_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>010-mllS7JL</td>\n",
              "      <td>14/14fe8812.jpg</td>\n",
              "      <td>010-mllS7JL</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01dkn0Gyx0L</td>\n",
              "      <td>da/daab0cad.jpg</td>\n",
              "      <td>01dkn0Gyx0L</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01sUPg0387L</td>\n",
              "      <td>d2/d2daaae9.jpg</td>\n",
              "      <td>01sUPg0387L</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1168jc-5r1L</td>\n",
              "      <td>3a/3a4e88e6.jpg</td>\n",
              "      <td>1168jc-5r1L</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11RUV5Fs65L</td>\n",
              "      <td>d9/d91ab9cf.jpg</td>\n",
              "      <td>617jhKkKz+L</td>\n",
              "      <td>GROCERY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11X4pFHqYOL</td>\n",
              "      <td>20/20098c4d.jpg</td>\n",
              "      <td>61DjvM0+EXL</td>\n",
              "      <td>GROCERY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11Y+Xpt1lfL</td>\n",
              "      <td>99/9987a1c8.jpg</td>\n",
              "      <td>11Y+Xpt1lfL</td>\n",
              "      <td>AV_FURNITURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11rL64ZLPYL</td>\n",
              "      <td>89/89a2ff4d.jpg</td>\n",
              "      <td>51vzzAy4C9L</td>\n",
              "      <td>HARDWARE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11xjmNF5TAL</td>\n",
              "      <td>ee/ee239f0f.jpg</td>\n",
              "      <td>11xjmNF5TAL</td>\n",
              "      <td>PET_SUPPLIES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11xkwXwrSXL</td>\n",
              "      <td>75/75536bf9.jpg</td>\n",
              "      <td>31G2EwHIWyL</td>\n",
              "      <td>GROCERY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_id             path main_image_id  product_type\n",
              "0  010-mllS7JL  14/14fe8812.jpg   010-mllS7JL       KITCHEN\n",
              "1  01dkn0Gyx0L  da/daab0cad.jpg   01dkn0Gyx0L       KITCHEN\n",
              "2  01sUPg0387L  d2/d2daaae9.jpg   01sUPg0387L       KITCHEN\n",
              "3  1168jc-5r1L  3a/3a4e88e6.jpg   1168jc-5r1L       KITCHEN\n",
              "4  11RUV5Fs65L  d9/d91ab9cf.jpg   617jhKkKz+L       GROCERY\n",
              "5  11X4pFHqYOL  20/20098c4d.jpg   61DjvM0+EXL       GROCERY\n",
              "6  11Y+Xpt1lfL  99/9987a1c8.jpg   11Y+Xpt1lfL  AV_FURNITURE\n",
              "7  11rL64ZLPYL  89/89a2ff4d.jpg   51vzzAy4C9L      HARDWARE\n",
              "8  11xjmNF5TAL  ee/ee239f0f.jpg   11xjmNF5TAL  PET_SUPPLIES\n",
              "9  11xkwXwrSXL  75/75536bf9.jpg   31G2EwHIWyL       GROCERY"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR9Vbovyq7N5",
        "outputId": "46c57324-5a68-41fc-f1b4-8885e8020b12"
      },
      "outputs": [],
      "source": [
        "merged_df.drop('image_id', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeVDqr7cgklx",
        "outputId": "5a0833ff-7ac6-4da9-807f-68c2978b0d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398212 entries, 0 to 398211\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   path           398212 non-null  object\n",
            " 1   main_image_id  397240 non-null  object\n",
            " 2   product_type   398170 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 9.1+ MB\n"
          ]
        }
      ],
      "source": [
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz3qMwkOvgt5"
      },
      "source": [
        "Se mergean los datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "im66fucEMuI4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import gzip\n",
        "\n",
        "# Vamos a juntar toda la metadata de cada item listado\n",
        "alt_data = []\n",
        "for filename in os.listdir(listings_metadata_dir):\n",
        "  if filename.endswith('.json.gz'):\n",
        "    with gzip.open(os.path.join(listings_metadata_dir, filename), 'rt', encoding='ascii') as f:\n",
        "      for line in f:\n",
        "        alt_data.append(json.loads(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVJYZKWYMvrR",
        "outputId": "79c8c56c-ad43-4e48-df40-1660abffdc77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'brand': [{'language_tag': 'nl_NL', 'value': 'find.'}],\n",
              " 'bullet_point': [{'language_tag': 'nl_NL', 'value': 'Schoen in Loafer-stijl'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'Platform hak'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'Cap teen'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'Middenhak'}],\n",
              " 'color': [{'language_tag': 'nl_NL', 'value': 'Veelkleurig Vrouw Blauw'}],\n",
              " 'item_id': 'B06X9STHNG',\n",
              " 'item_name': [{'language_tag': 'nl_NL',\n",
              "   'value': 'Amazon-merk - vinden. Dames Leder Gesloten Teen Hakken,Veelkleurig Vrouw Blauw,5 UK'}],\n",
              " 'model_name': [{'language_tag': 'nl_NL', 'value': '37753'}],\n",
              " 'model_number': [{'value': '12-05-04'}],\n",
              " 'model_year': [{'value': 2017}],\n",
              " 'product_type': [{'value': 'SHOES'}],\n",
              " 'style': [{'language_tag': 'nl_NL', 'value': 'Gesloten-teen pompen'}],\n",
              " 'main_image_id': '81iZlv3bjpL',\n",
              " 'other_image_id': ['91mIRxgziUL', '91eqBkW06wL', 'A1BHZSKNbkL'],\n",
              " 'item_keywords': [{'language_tag': 'nl_NL', 'value': 'block heel shoes'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'loafer shoes'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'loafers'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'metallic shoes'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'womens block heel shoes'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'womens fashion'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'womens loafer shoes'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'womens loafers'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'womens shoes'},\n",
              "  {'language_tag': 'nl_NL', 'value': 'womenswear'}],\n",
              " 'country': 'NL',\n",
              " 'marketplace': 'Amazon',\n",
              " 'domain_name': 'amazon.nl',\n",
              " 'node': [{'node_id': 16391787031,\n",
              "   'node_name': '/Categorieën/Dames/Schoenen/Pumps'}]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listemos un item para ver su formato\n",
        "alt_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTNTdaruM34Q",
        "outputId": "2aaf0b35-98d9-433e-fc2d-05ef306a5719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398212 entries, 0 to 398211\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   path           398212 non-null  object\n",
            " 1   main_image_id  397240 non-null  object\n",
            " 2   product_type   398170 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 9.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Visualizamos nuestro progreso\n",
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X2fqIIGE3Nyj",
        "outputId": "1d3d3784-1a16-40ca-e483-4cadd85bd68f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>main_image_id</th>\n",
              "      <th>product_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14/14fe8812.jpg</td>\n",
              "      <td>010-mllS7JL</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>da/daab0cad.jpg</td>\n",
              "      <td>01dkn0Gyx0L</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d2/d2daaae9.jpg</td>\n",
              "      <td>01sUPg0387L</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3a/3a4e88e6.jpg</td>\n",
              "      <td>1168jc-5r1L</td>\n",
              "      <td>KITCHEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d9/d91ab9cf.jpg</td>\n",
              "      <td>617jhKkKz+L</td>\n",
              "      <td>GROCERY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              path main_image_id product_type\n",
              "0  14/14fe8812.jpg   010-mllS7JL      KITCHEN\n",
              "1  da/daab0cad.jpg   01dkn0Gyx0L      KITCHEN\n",
              "2  d2/d2daaae9.jpg   01sUPg0387L      KITCHEN\n",
              "3  3a/3a4e88e6.jpg   1168jc-5r1L      KITCHEN\n",
              "4  d9/d91ab9cf.jpg   617jhKkKz+L      GROCERY"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxxhLu1seJO"
      },
      "source": [
        "Se realizan un preprocesado para tomar etiqueatas que solo tengan mas de 1500 filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (10.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(290575, 3)\n",
            "              path main_image_id product_type\n",
            "0  14/14fe8812.jpg   010-mllS7JL      KITCHEN\n",
            "1  da/daab0cad.jpg   01dkn0Gyx0L      KITCHEN\n",
            "2  d2/d2daaae9.jpg   01sUPg0387L      KITCHEN\n",
            "3  3a/3a4e88e6.jpg   1168jc-5r1L      KITCHEN\n",
            "4  d9/d91ab9cf.jpg   617jhKkKz+L      GROCERY\n",
            "(290575, 3)\n",
            "product_type\n",
            "CELLULAR_PHONE_CASE                 116771\n",
            "SHOES                                33804\n",
            "GROCERY                              26291\n",
            "HOME                                 21534\n",
            "CHAIR                                10770\n",
            "SOFA                                  6052\n",
            "HEALTH_PERSONAL_CARE                  5587\n",
            "TABLE                                 4840\n",
            "HANDBAG                               4564\n",
            "PET_SUPPLIES                          4368\n",
            "HARDWARE_HANDLE                       4234\n",
            "KITCHEN                               3359\n",
            "SPORTING_GOODS                        3341\n",
            "LAMP                                  3236\n",
            "SANDAL                                2973\n",
            "BOOT                                  2856\n",
            "LIGHT_FIXTURE                         2820\n",
            "FINENECKLACEBRACELETANKLET            2641\n",
            "RUG                                   2523\n",
            "LIGHT_BULB                            2315\n",
            "OUTDOOR_LIVING                        2243\n",
            "STOOL_SEATING                         2217\n",
            "SUITCASE                              2195\n",
            "FINEEARRING                           2049\n",
            "ACCESSORY                             1885\n",
            "FINERING                              1863\n",
            "TOOLS                                 1774\n",
            "JANITORIAL_SUPPLY                     1752\n",
            "OTTOMAN                               1752\n",
            "BEAUTY                                1693\n",
            "PORTABLE_ELECTRONIC_DEVICE_COVER      1678\n",
            "WALL_ART                              1537\n",
            "SHELF                                 1531\n",
            "CABINET                               1527\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supongamos que tu DataFrame se llama merged_df\n",
        "# Contar la cantidad de imágenes por etiqueta\n",
        "label_counts = merged_df['product_type'].value_counts()\n",
        "\n",
        "# Filtrar las etiquetas con menos de 1500 imágenes\n",
        "labels_to_keep = label_counts[label_counts >= 1500].index\n",
        "\n",
        "# Filtrar el DataFrame original para mantener solo las filas con etiquetas que tienen al menos 1500 imágenes\n",
        "df_filtered = merged_df[merged_df['product_type'].isin(labels_to_keep)]\n",
        "\n",
        "# Eliminar las etiquetas especificadas\n",
        "labels_to_remove = [\n",
        "    'HOME_FURNITURE_AND_DECOR', 'FURNITURE_COVER', 'AUTO_ACCESSORY',\n",
        "    'PANTRY', 'COMPUTER_ADD_ON', 'HARDWARE', 'STORAGE_BINDER','OFFICE_PRODUCTS'\n",
        "]\n",
        "df_filtered = df_filtered[~df_filtered['product_type'].isin(labels_to_remove)]\n",
        "\n",
        "# Fusionar las etiquetas especificadas\n",
        "# Primero renombrar 'HOME_BED_AND_BATH' a 'HOME'\n",
        "df_filtered['product_type'] = df_filtered['product_type'].replace({'HOME_BED_AND_BATH': 'HOME'})\n",
        "\n",
        "# Verificar el tamaño del nuevo DataFrame\n",
        "print(df_filtered.shape)\n",
        "\n",
        "# Verificar las primeras filas del nuevo DataFrame\n",
        "print(df_filtered.head())\n",
        "\n",
        "# Mostrar el tamaño y conteo de etiquetas del DataFrame filtrado\n",
        "print(df_filtered.shape)\n",
        "print(df_filtered['product_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "product_type\n",
            "CELLULAR_PHONE_CASE                 116771\n",
            "SHOES                                33804\n",
            "GROCERY                              26291\n",
            "HOME                                 21534\n",
            "CHAIR                                10770\n",
            "SOFA                                  6052\n",
            "HEALTH_PERSONAL_CARE                  5587\n",
            "TABLE                                 4840\n",
            "HANDBAG                               4564\n",
            "PET_SUPPLIES                          4368\n",
            "HARDWARE_HANDLE                       4234\n",
            "KITCHEN                               3359\n",
            "SPORTING_GOODS                        3341\n",
            "LAMP                                  3236\n",
            "SANDAL                                2973\n",
            "BOOT                                  2856\n",
            "LIGHT_FIXTURE                         2820\n",
            "FINENECKLACEBRACELETANKLET            2641\n",
            "RUG                                   2523\n",
            "LIGHT_BULB                            2315\n",
            "OUTDOOR_LIVING                        2243\n",
            "STOOL_SEATING                         2217\n",
            "SUITCASE                              2195\n",
            "FINEEARRING                           2049\n",
            "ACCESSORY                             1885\n",
            "FINERING                              1863\n",
            "TOOLS                                 1774\n",
            "JANITORIAL_SUPPLY                     1752\n",
            "OTTOMAN                               1752\n",
            "BEAUTY                                1693\n",
            "PORTABLE_ELECTRONIC_DEVICE_COVER      1678\n",
            "WALL_ART                              1537\n",
            "SHELF                                 1531\n",
            "CABINET                               1527\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_filtered['product_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(290575, 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_filtered.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from imblearn) (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(290575, 3)\n",
            "product_type\n",
            "CELLULAR_PHONE_CASE                 116771\n",
            "SHOES                                33804\n",
            "GROCERY                              26291\n",
            "HOME                                 21534\n",
            "CHAIR                                10770\n",
            "SOFA                                  6052\n",
            "HEALTH_PERSONAL_CARE                  5587\n",
            "TABLE                                 4840\n",
            "HANDBAG                               4564\n",
            "PET_SUPPLIES                          4368\n",
            "HARDWARE_HANDLE                       4234\n",
            "KITCHEN                               3359\n",
            "SPORTING_GOODS                        3341\n",
            "LAMP                                  3236\n",
            "SANDAL                                2973\n",
            "BOOT                                  2856\n",
            "LIGHT_FIXTURE                         2820\n",
            "FINENECKLACEBRACELETANKLET            2641\n",
            "RUG                                   2523\n",
            "LIGHT_BULB                            2315\n",
            "OUTDOOR_LIVING                        2243\n",
            "STOOL_SEATING                         2217\n",
            "SUITCASE                              2195\n",
            "FINEEARRING                           2049\n",
            "ACCESSORY                             1885\n",
            "FINERING                              1863\n",
            "TOOLS                                 1774\n",
            "JANITORIAL_SUPPLY                     1752\n",
            "OTTOMAN                               1752\n",
            "BEAUTY                                1693\n",
            "PORTABLE_ELECTRONIC_DEVICE_COVER      1678\n",
            "WALL_ART                              1537\n",
            "SHELF                                 1531\n",
            "CABINET                               1527\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Supongamos que tu DataFrame se llama df_filtered\n",
        "print(df_filtered.shape)\n",
        "print(df_filtered['product_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seteamos un maximo de 2000 fotos por cateogia, utiliando random sampler "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma y distribución de clases antes del submuestreo:\n",
            "(290575, 3)\n",
            "product_type\n",
            "CELLULAR_PHONE_CASE                 116771\n",
            "SHOES                                33804\n",
            "GROCERY                              26291\n",
            "HOME                                 21534\n",
            "CHAIR                                10770\n",
            "SOFA                                  6052\n",
            "HEALTH_PERSONAL_CARE                  5587\n",
            "TABLE                                 4840\n",
            "HANDBAG                               4564\n",
            "PET_SUPPLIES                          4368\n",
            "HARDWARE_HANDLE                       4234\n",
            "KITCHEN                               3359\n",
            "SPORTING_GOODS                        3341\n",
            "LAMP                                  3236\n",
            "SANDAL                                2973\n",
            "BOOT                                  2856\n",
            "LIGHT_FIXTURE                         2820\n",
            "FINENECKLACEBRACELETANKLET            2641\n",
            "RUG                                   2523\n",
            "LIGHT_BULB                            2315\n",
            "OUTDOOR_LIVING                        2243\n",
            "STOOL_SEATING                         2217\n",
            "SUITCASE                              2195\n",
            "FINEEARRING                           2049\n",
            "ACCESSORY                             1885\n",
            "FINERING                              1863\n",
            "TOOLS                                 1774\n",
            "JANITORIAL_SUPPLY                     1752\n",
            "OTTOMAN                               1752\n",
            "BEAUTY                                1693\n",
            "PORTABLE_ELECTRONIC_DEVICE_COVER      1678\n",
            "WALL_ART                              1537\n",
            "SHELF                                 1531\n",
            "CABINET                               1527\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Forma y distribución de clases después del submuestreo:\n",
            "(64992, 3)\n",
            "product_type\n",
            "LIGHT_BULB                          2000\n",
            "SANDAL                              2000\n",
            "SHOES                               2000\n",
            "PET_SUPPLIES                        2000\n",
            "OUTDOOR_LIVING                      2000\n",
            "SOFA                                2000\n",
            "LIGHT_FIXTURE                       2000\n",
            "SPORTING_GOODS                      2000\n",
            "LAMP                                2000\n",
            "KITCHEN                             2000\n",
            "STOOL_SEATING                       2000\n",
            "HOME                                2000\n",
            "HEALTH_PERSONAL_CARE                2000\n",
            "HARDWARE_HANDLE                     2000\n",
            "HANDBAG                             2000\n",
            "GROCERY                             2000\n",
            "SUITCASE                            2000\n",
            "FINENECKLACEBRACELETANKLET          2000\n",
            "FINEEARRING                         2000\n",
            "CHAIR                               2000\n",
            "CELLULAR_PHONE_CASE                 2000\n",
            "TABLE                               2000\n",
            "BOOT                                2000\n",
            "RUG                                 2000\n",
            "ACCESSORY                           1885\n",
            "FINERING                            1863\n",
            "TOOLS                               1774\n",
            "OTTOMAN                             1752\n",
            "JANITORIAL_SUPPLY                   1752\n",
            "BEAUTY                              1693\n",
            "PORTABLE_ELECTRONIC_DEVICE_COVER    1678\n",
            "WALL_ART                            1537\n",
            "SHELF                               1531\n",
            "CABINET                             1527\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verificar la existencia del DataFrame df_filtered\n",
        "if 'df_filtered' not in locals():\n",
        "    raise ValueError(\"El DataFrame 'df_filtered' no está definido.\")\n",
        "\n",
        "# Mostrar la forma y la distribución de clases antes del submuestreo\n",
        "print(\"Forma y distribución de clases antes del submuestreo:\")\n",
        "print(df_filtered.shape)\n",
        "print(df_filtered['product_type'].value_counts())\n",
        "\n",
        "# Establecer el número objetivo de muestras por clase\n",
        "n_target_samples = 2000  # Ajustar según tus necesidades\n",
        "\n",
        "# Separar las características y la etiqueta\n",
        "X = df_filtered.drop('product_type', axis=1)\n",
        "y = df_filtered['product_type']\n",
        "\n",
        "# Verificar y ajustar el sampling_strategy\n",
        "sampling_strategy = {label: n_target_samples for label in y.value_counts().index if y.value_counts()[label] > n_target_samples}\n",
        "rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
        "\n",
        "# Aplicar RandomUnderSampler\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "# Crear un nuevo DataFrame con los datos submuestreados\n",
        "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "# Mostrar la forma y la distribución de clases después del submuestreo\n",
        "print(\"\\nForma y distribución de clases después del submuestreo:\")\n",
        "print(df_resampled.shape)\n",
        "print(df_resampled['product_type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64992, 3)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  path main_image_id product_type  \\\n",
            "1944   d5/d5016e4f.jpg   6157GiHRZlL    ACCESSORY   \n",
            "4926   2c/2c670948.jpg   31f5qkdb-nL    ACCESSORY   \n",
            "7835   d4/d45e3afe.jpg   417zqxz9R8L    ACCESSORY   \n",
            "7865   34/34f5dcba.jpg   51TofVnlDfL    ACCESSORY   \n",
            "9501   36/36c8e3ac.jpg   41MOc6PMD6L    ACCESSORY   \n",
            "9582   d8/d8da1077.jpg   41N8yQVL7tL    ACCESSORY   \n",
            "10377  35/35fc0f73.jpg   41TonIVJUWL    ACCESSORY   \n",
            "10418  dd/dd7f9b9c.jpg   41U3r0psRPL    ACCESSORY   \n",
            "10711  41/41da6598.jpg   41WgI-vZSFL    ACCESSORY   \n",
            "10712  3c/3ceac609.jpg   41WgOG2IrZL    ACCESSORY   \n",
            "\n",
            "                          full_path  \n",
            "1944   images/small/d5/d5016e4f.jpg  \n",
            "4926   images/small/2c/2c670948.jpg  \n",
            "7835   images/small/d4/d45e3afe.jpg  \n",
            "7865   images/small/34/34f5dcba.jpg  \n",
            "9501   images/small/36/36c8e3ac.jpg  \n",
            "9582   images/small/d8/d8da1077.jpg  \n",
            "10377  images/small/35/35fc0f73.jpg  \n",
            "10418  images/small/dd/dd7f9b9c.jpg  \n",
            "10711  images/small/41/41da6598.jpg  \n",
            "10712  images/small/3c/3ceac609.jpg  \n"
          ]
        }
      ],
      "source": [
        "base_dir = 'images/small'\n",
        "\n",
        "# Verificar la existencia de la columna 'path' y corregir las rutas de las imágenes\n",
        "if 'path' not in df_resampled.columns:\n",
        "    raise ValueError(\"La columna 'path' no está presente en 'df_resampled'.\")\n",
        "df_resampled['full_path'] = df_resampled['path'].apply(lambda x: os.path.join(base_dir, x).replace(\"\\\\\", \"/\"))\n",
        "\n",
        "# Verificar que las rutas de las imágenes sean correctas\n",
        "if not all(os.path.exists(path) for path in df_resampled['full_path']):\n",
        "    raise ValueError(\"Algunas rutas de imágenes no existen.\")\n",
        "\n",
        "# Verificar las primeras filas después de la corrección\n",
        "print(df_resampled.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ajustar el LabelEncoder y codificar las etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 path main_image_id product_type  \\\n",
            "1944  d5/d5016e4f.jpg   6157GiHRZlL    ACCESSORY   \n",
            "4926  2c/2c670948.jpg   31f5qkdb-nL    ACCESSORY   \n",
            "7835  d4/d45e3afe.jpg   417zqxz9R8L    ACCESSORY   \n",
            "7865  34/34f5dcba.jpg   51TofVnlDfL    ACCESSORY   \n",
            "9501  36/36c8e3ac.jpg   41MOc6PMD6L    ACCESSORY   \n",
            "\n",
            "                         full_path  label  \n",
            "1944  images/small/d5/d5016e4f.jpg      0  \n",
            "4926  images/small/2c/2c670948.jpg      0  \n",
            "7835  images/small/d4/d45e3afe.jpg      0  \n",
            "7865  images/small/34/34f5dcba.jpg      0  \n",
            "9501  images/small/36/36c8e3ac.jpg      0  \n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_resampled['label'] = label_encoder.fit_transform(df_resampled['product_type'])\n",
        "\n",
        "# Guardar el LabelEncoder en un archivo\n",
        "with open('label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "# Verificar las primeras filas después de la codificación\n",
        "print(df_resampled.head())\n",
        "\n",
        "# Crear un tf.data.Dataset\n",
        "paths = df_resampled['full_path'].values\n",
        "labels = df_resampled['label'].values\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64992, 5)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configurar el credimento de memoria y funcion para cargar imagenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configurar TensorFlow para silenciar las advertencias\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "# Directorio base donde se encuentran las imágenes\n",
        "base_dir = 'images/small'\n",
        "\n",
        "# Verificar la disponibilidad de GPUs\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Configurar el crecimiento de la memoria\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Crear una función para cargar y preprocesar las imágenes\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0  # Normalizar a [0, 1]\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo con su estrucura mencionabda en el informe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "Physical devices cannot be modified after being initialized\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Dividir los datos en entrenamiento y validación (80%-20%)\n",
        "train_df, val_df = train_test_split(df_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear datasets de TensorFlow\n",
        "train_paths = train_df['full_path'].values\n",
        "train_labels = train_df['label'].values\n",
        "val_paths = val_df['full_path'].values\n",
        "val_labels = val_df['label'].values\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "\n",
        "# Aplicar las transformaciones a los datasets\n",
        "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Preparar los datasets\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_df)).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Crear un modelo de aumento de datos\n",
        "data_augmentation = Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomRotation(factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
        "        tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
        "        tf.keras.layers.RandomZoom(height_factor=(0.2, 0.3), fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
        "        tf.keras.layers.Resizing(height=224, width=224, interpolation=\"bilinear\"),\n",
        "        tf.keras.layers.RandomFlip(mode=\"horizontal\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Crear el modelo base VGG16 preentrenado en ImageNet sin la capa superior\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Congelar las capas del modelo base\n",
        "\n",
        "# Añadir nuevas capas para nuestro problema de clasificación\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Configurar TensorBoard\n",
        "log_dir = \"logs/fit/\" + str(int(tf.timestamp()))\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Definir otros callbacks\n",
        "class CustomPrintCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f'Epoch {epoch + 1}:')\n",
        "        for key, value in logs.items():\n",
        "            print(f'{key}: {value:.4f}')\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('model_bestv2.h5', save_best_only=True, monitor='val_loss'),\n",
        "    EarlyStopping(monitor='val_loss', patience=5),\n",
        "    tensorboard_callback,\n",
        "    CustomPrintCallback()\n",
        "]\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Descongelar algunas capas del modelo base para ajuste fino\n",
        "base_model.trainable = True\n",
        "fine_tune_at = len(base_model.layers) - 20  # Número de capas a descongelar\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar el modelo nuevamente\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continuar entrenando\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Post procesamiento y gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xZ7y0fN6Zkg"
      },
      "outputs": [],
      "source": [
        "# Graficar el entrenamiento y validación de pérdida\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Graficar pérdida\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Entrenamiento (Training) Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validación (Validation) Loss')\n",
        "plt.plot(range(len(history.history['loss']), len(history.history['loss']) + len(history_fine.history['loss'])), history_fine.history['loss'], label='Entrenamiento Ajuste Fino (Training Fine-tuning) Loss')\n",
        "plt.plot(range(len(history.history['val_loss']), len(history.history['val_loss']) + len(history_fine.history['val_loss'])), history_fine.history['val_loss'], label='Validación Ajuste Fino (Validation Fine-tuning) Loss')\n",
        "plt.title('Pérdida durante el entrenamiento y la validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Graficar precisión\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Entrenamiento (Training) Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validación (Validation) Accuracy')\n",
        "plt.plot(range(len(history.history['accuracy']), len(history.history['accuracy']) + len(history_fine.history['accuracy'])), history_fine.history['accuracy'], label='Entrenamiento Ajuste Fino (Training Fine-tuning) Accuracy')\n",
        "plt.plot(range(len(history.history['val_accuracy']), len(history.history['val_accuracy']) + len(history_fine.history['val_accuracy'])), history_fine.history['val_accuracy'], label='Validación Ajuste Fino (Validation Fine-tuning) Accuracy')\n",
        "plt.title('Precisión durante el entrenamiento y la validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Obtener las predicciones del modelo en el conjunto de validación\n",
        "val_labels_pred = model.predict(val_dataset)\n",
        "val_labels_pred = np.argmax(val_labels_pred, axis=1)\n",
        "\n",
        "# Obtener las etiquetas reales del conjunto de validación\n",
        "val_labels_true = np.concatenate([y for x, y in val_dataset], axis=0)\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "conf_matrix = confusion_matrix(val_labels_true, val_labels_pred)\n",
        "\n",
        "# Ajustar el tamaño de la figura\n",
        "fig, ax = plt.subplots(figsize=(15, 15))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)\n",
        "disp.plot(include_values=True, cmap='viridis', ax=ax, xticks_rotation='vertical')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar el modelo en el conjunto de validación\n",
        "val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "print(f\"Loss en validación: {val_loss}\")\n",
        "print(f\"Precisión en validación: {val_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('modeloProduct_typeV2.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\delp\\miniconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import pickle\n",
        "\n",
        "# Configurar TensorFlow para silenciar las advertencias\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = tf.keras.models.load_model('modeloProduct_typeV2.h5')\n",
        "\n",
        "# Cargar el LabelEncoder desde el archivo\n",
        "with open('label_encoder.pkl', 'rb') as file:\n",
        "    label_encoder = pickle.load(file)\n",
        "\n",
        "# Definir la función de predicción\n",
        "def predict_image(image):\n",
        "    # Preprocesar la imagen\n",
        "    image = image.resize((224, 224))\n",
        "    image_array = np.array(image) / 255.0\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    # Obtener la predicción del modelo\n",
        "    predictions = model.predict(image_array)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Mapear el índice de la clase predicha a la etiqueta correspondiente\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Crear la interfaz con Gradio usando la nueva API\n",
        "gr_interface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(type='pil', label='Sube una imagen'),\n",
        "    outputs=gr.Textbox(label='Predicción')\n",
        ")\n",
        "\n",
        "# Lanzar la interfaz\n",
        "gr_interface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
